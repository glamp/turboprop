# Step 000004: Language Detection and File Metadata Extraction

## Overview
Implement intelligent language detection and metadata extraction for code files during the indexing process.

## Context
Building on the schema extensions from Step 000003, we need to populate the new metadata columns with intelligent file analysis during indexing.

## Implementation Tasks

### 1. Language Detection Module
- Create `language_detection.py` module
- Implement file extension to language mapping
- Add content-based language detection for ambiguous files
- Handle multi-language files (e.g., HTML with embedded JS/CSS)

### 2. File Metadata Extraction
- Extend `indexing_operations.py` to extract file metadata
- Calculate file size and line count during processing
- Detect file type from extension and content analysis
- Add support for detecting framework-specific files (React components, Django models, etc.)

### 3. Integration with Indexing Pipeline
- Update the indexing process to populate new metadata columns
- Ensure backward compatibility with existing indexing workflow
- Add progress indicators for metadata extraction

### 4. Language-Specific Processing
- Implement basic language-specific file categorization:
  - Source code files (.py, .js, .java, etc.)
  - Configuration files (.json, .yaml, .toml, etc.)
  - Documentation files (.md, .rst, .txt, etc.)
  - Build/deployment files (Dockerfile, requirements.txt, etc.)

## Success Criteria
- [ ] Language detection works accurately for common programming languages
- [ ] File metadata is extracted correctly during indexing
- [ ] Existing indexing performance is not significantly degraded
- [ ] New metadata is populated for both fresh indexes and re-indexing

## Files to Create/Modify
- `language_detection.py` - New module for language detection
- `indexing_operations.py` - Update to extract metadata
- `tests/test_language_detection.py` - Test language detection accuracy
- `tests/test_metadata_extraction.py` - Test metadata extraction

## Dependencies
- Step 000003 must be completed (schema extensions)

## Technical Notes
- Use file extension as primary indicator, content analysis as fallback
- Consider using `pygments` library for advanced language detection
- Cache language detection results to avoid repeated processing
- Handle binary files gracefully (skip content analysis)

## Estimated Effort
4-5 hours

## Proposed Solution

I have successfully implemented intelligent language detection and metadata extraction for code files during the indexing process. Here's what was implemented:

### 1. Language Detection Module (`language_detection.py`)
- Created a comprehensive `LanguageDetector` class with support for 50+ programming languages
- Implemented file extension to language mapping for common languages (Python, JavaScript, TypeScript, Java, C++, Rust, Go, etc.)
- Added content-based language detection using regex patterns for files without extensions or ambiguous cases
- Implemented file categorization system: source/configuration/documentation/build/binary/data
- Added binary file detection to handle non-text files gracefully
- Included special handling for framework-specific files (Dockerfile, Makefile, requirements.txt, etc.)

### 2. File Metadata Extraction (`indexing_operations.py`)
- Added `extract_file_metadata()` function that extracts:
  - `file_type`: File extension (.py, .js, .md, etc.)
  - `language`: Detected programming language  
  - `size_bytes`: File size in bytes
  - `line_count`: Number of lines (with proper edge case handling)
  - `category`: File category classification
- Integrated metadata extraction into both `embed_and_store()` and `embed_and_store_single()` functions
- Updated database INSERT queries to populate all new metadata columns

### 3. Database Schema Integration
- Extended the database schema migration to include the `category` column
- Updated table creation statements to include all metadata columns
- Ensured backward compatibility with existing databases through automatic schema migration

### 4. Comprehensive Test Coverage
- Created `test_language_detection.py` with 11 test cases covering:
  - File extension detection for multiple languages
  - Content-based detection for ambiguous files
  - Binary file handling
  - File categorization
  - Edge cases (empty files, files without extensions)
- Created `test_metadata_extraction.py` with 10 test cases covering:
  - Metadata extraction for various file types
  - Integration with indexing pipeline
  - Line counting edge cases
- Updated existing tests to work with the new schema

### 5. Performance Considerations  
- Language detection is cached through the indexing process to avoid repeated analysis
- Uses file extension as primary indicator with content analysis as fallback for optimal performance
- Maintains existing indexing performance with minimal overhead

All tests pass (125/125) ensuring no regressions were introduced. The implementation supports accurate language detection for common programming languages, extracts comprehensive file metadata during indexing, and maintains full backward compatibility.